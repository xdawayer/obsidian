我有个毛病。书架上的书越买越多，真正翻开的越来越少。

每次看到书单推荐，先收藏。然后就没有然后了。

收藏夹里躺着几百本"想看的书"，它们唯一的作用是偶尔跳出来提醒我：你又没看。

这种焦虑很低级。但很真实。

尤其做 AI 之后，天天追新工具、追新模型、追新玩法。信息流刷不完，技术变化追不上。哪还有心思坐下来看书？

但春节假期，事情少了，人也闲下来了。我就想：既然我能用 AI 做占星网站，能不能做个帮我拆书的工具？

---

## 起点：一个想偷懒的念头

起因很简单。

我想看的书太多，但没时间一本本读。如果有个工具能帮我把每本书的核心内容拆出来，我先看拆解，感兴趣再去读原书——至少比躺在收藏夹里强。

说干就干。打开 Claude，开始写 prompt。

想法很美好。现实嘛……

---

## 提示词地狱：4万字还是救不了

一开始，我以为写个好 prompt 就够了。

毕竟拆书这事不复杂嘛——告诉 AI 这本书讲什么、核心观点是什么、有什么值得记住的，输出一篇读书笔记。

然后我就掉进了一个坑：prompt 越写越长，效果越来越不可控。

先是格式问题。输出的加粗到处乱飞，标题层级一会儿二级一会儿四级，排版像被风吹过的报纸。

然后是字数问题。我说"这个模块至少200字"，它有时候给你50字就收了。我说"总字数不少于5000字"，它写到3000字开始注水，最后一段全是废话。

再然后是内容问题。AI 把各种分析方法直接写进正文——"运用第一性原理分析""通过 DIKW 框架可以看出"。

读起来像什么？像在读一篇论文。不，像在读一篇 AI 写的论文。

我就一个需求：写得像一个读过这本书的聪明朋友在跟我聊天。结果它给我的是一个在答辩的研究生。

为了解决这些问题，我设计了拆解流程，定义每个阶段的内容重点和输出要求。还是不够。又开始一条一条补规则。

"这个部分不少于200字。"
"禁止在正文中出现任何分析方法的名称。"
"加粗只用在核心观点首次出现时。"

补着补着，prompt 膨胀到了4-5万字。

4万字的提示词，就为了让 AI 好好写篇读书笔记。想想都觉得荒谬。

而且效果还是一般。像在堵漏——这边堵上了，那边又漏了。

<!-- 📸 配图位置：prompt 截图或字数统计截图，展示4万字的视觉冲击 -->

---

## 转折：从提示词到 skill

后来 Claude Code 出了 skill 功能。

这东西改变了我做这件事的方式——不是改进，是彻底换了个思路。

之前用 prompt，相当于我自己在做。每次生成我都得盯着，发现问题改 prompt，改完再跑，循环往复。

**用 skill 之后，我的角色变了。我不再是执行者，我是需求方和验证方。**

我告诉 Claude Code 我要什么效果，它来写 skill，来设计流程，来拆分模块。我去用、去读、去挑毛病。

这个转变很大。

具体来说，skill 解决了 prompt 解决不了的几个问题：

prompt 是一坨文字，改到后面自己都看不清哪段管什么。skill 是结构化的——主文件定义流程，references 放风格指南和范例，scripts 放验证脚本。改哪里改哪里，不会牵一发动全身。

prompt 改一次要手动重新跑。skill 改完直接生效，下次调用自动走新版本。

最关键的是验证。prompt 时代我只能靠眼睛看"这篇笔记有没有问题"。现在有验证脚本——字数够不够、格式对不对、有没有出现禁止的 AI 用语——自动检查，不用我一篇篇盯。

**教训：流程标准化 >> 提示词完美化。**

prompt 写到4万字也不如一套结构化的流程管用。这是我踩完坑之后最大的认知。

<!-- 📸 配图位置：prompt vs skill 的对比图，或 skill 文件结构截图 -->

---

## 调到 v7：58项检测，10本书一次通过

角色转变之后，迭代速度快了很多。

主要是老板在推。她自己爱看书，拿着生成的读书笔记逐条看，反馈非常直接。

"太长了，谁看得完。"

"这段明显是 AI 写的，正常人不这么说话。"

"方法论味太重，我想看的是这本书讲了什么，不是你用了什么分析工具。"

每条反馈都变成了一次迭代。

逐渐加上了10来种拆解方法（但全部隐藏在内部，绝不出现在正文里）、17种书籍类型的差异化模板（文学和经济学的拆法肯定不一样）、验证脚本从十几项扩展到58项。

现在的效果：10本书一次性生成，58项检测全部通过，不用人工干预。

当然也不是完美的。加粗滥用的问题时不时还会冒出来——这个可能是 AI 的通病，到现在也没完全根治。还有些书的拆解偏工具化，缺少那种真正的阅读感。

**每本书都是一个故事。我不想用一个通用的框架去量化所有故事。** 这是下一步要解决的问题。

<!-- 📸 配图位置：验证脚本运行截图，或一次性通过58项检测的结果 -->

---

## 264本书

从《金刚经》到《三体》，从《资本论》到《鞋狗》。264本，17个分类。

哲学、文学、经济、商业、历史、心理学、传记、科普……基本上你想到的经典书，大概率都有。

生成速度也还行。10个 subagent 并行跑，半小时差不多出10本。Claude 20x 的每天5小时额度，经常跑着跑着就到顶了。

成本嘛，主要是时间。订阅费是固定的，不像做网站那样按 token 烧钱。

有一天我把这些读书笔记整理了一下，突然觉得：这东西放在自己电脑里也是放着。不如分享出去。

小红书上搜了下，类似的 AI 读书笔记，有人卖20-30块一份。

我选择免费。

放在了 ima 上——腾讯的一个知识库工具，有点像 Google 的 NotebookLM。下载 app，扫码加入就能看。

后续打算做个微信小程序，方便没有 ima 的朋友用。我有朋友在美区，用不了 ima，挺尴尬的。

<!-- 📸 配图位置：ima 知识库截图，展示书目列表 -->

---

## 意外收获：我开始看书了

说实话，做这个工具的初衷就是偷懒。

"不用读原书也能了解内容"——这是我最开始的想法。

但264本书拆下来，一个很奇怪的事情发生了。

有些书看完拆解就够了。比如一些工具方法类的书，核心观点拆完，记住就行，不需要通读。

但有些书，看完拆解反而更想读原书了。

拆解里引了一段《活着》的描写，关于有庆赤脚跑步那段。几句话就让我停下来想了很久。然后我把原书翻出来了。

还有一次，看完《金刚经》的拆解。里面一句"一切有为法，如梦幻泡影"，在读书笔记的语境里读到，和在朋友圈看到别人转发，感觉完全不一样。

那天晚上我把《金刚经》的原文找出来，从头读了一遍。

不为什么。就是觉得应该慢下来看看。

做 AI 这段时间，天天在追效率。追新工具、追新模型、追产出速度。脑子里全是"更快""更多""更高效"。

偶尔看看书，心能静下来。

**这是做这个工具最大的意外收获。不是264本书的笔记，是我自己开始看书了。**

---

## 最后

现在回想，这个 skill 从提示词时代的4万字补丁到 v7.0 的58项自动检测，技术上确实进步不小。

但如果你问我"最大的收获是什么"，我不会说264本书，不会说17个分类，也不会说58项检测。

我会说：我终于不焦虑了。

不是因为看完了264本书——那些是 AI 看的，不是我。

而是因为我知道，那些书就在那里。想看的时候，先翻翻拆解，找到真正想读的，然后慢慢看。

不急。

AI 让一切都可以很快。但有些东西，就是需要慢下来。

偶尔看看书，对自己挺好的。

---

读书笔记我放在了 ima 上，264本，免费。

想看的扫这个码就行：

<!-- 📸 配图位置：ima 二维码 -->

（后续小程序做好了会再更新，让海外的朋友也能用上）
