---
title: "《我看见的世界》深度读书笔记"
author: "李飞飞"
tags:
  - 读书笔记
  - 传记回忆录
date_read: 2026-02-23
type: 传记回忆录
---

# 《我看见的世界》深度读书笔记

> [!abstract]
> 一个在成都长大的女孩，十六岁跟着父母移民美国，住在新泽西的小公寓里，一边在中餐馆洗盘子一边准备大学申请。二十多年后，她成了斯坦福大学教授、ImageNet的缔造者、谷歌云的首席科学家，被称为"AI教母"。李飞飞的故事不是一个天才横空出世的传说——它更像一部关于好奇心如何穿越贫困、孤独、学术偏见和身份焦虑的漫长旅程。这本自传同时也是一部AI简史的亲历者叙述：从学术界不看好计算机视觉的冷门岁月，到ImageNet意外引爆深度学习革命，再到整个世界开始认真思考AI将把人类带向何方。她站在这段历史的核心位置，但她最在意的问题不是"AI能做什么"，而是"AI应当为谁而做"。这本书既是一个移民女性的奋斗史，也是一面镜子，映照出科技发展中那些容易被遗忘的人性维度。

## 人物定位

李飞飞在AI领域占据着一个独特而不可替代的位置。她不是最早的深度学习研究者，不是算力革命的推动者，也不是商业帝国的缔造者——但她做了一件所有人都认为不重要、甚至不可能的事：==建造了一个足够大、足够好的数据集，让机器学习真正"看见"了世界==。在AI的历史叙事中，人们更多地谈论算法的突破和算力的飞跃，而ImageNet的贡献经常被简化为"一个数据库"。但如果没有这一千四百万张经过人工标注的图片，2012年的深度学习革命是否会在那个时间点发生，是一个没有人能给出确定答案的问题。

她同时是AI领域最早且最有影响力的"人文主义者"之一。在大多数技术领袖忙着谈论AI的效率和利润时，她在斯坦福创建了以人为本AI研究院（HAI），把哲学家、伦理学家、社会科学家拉进了关于AI未来的对话。这个选择在当时看来几乎是自找麻烦——你已经在技术上站到了顶峰，为什么要引入那些会拖慢速度、增加复杂性的"非技术"声音？但李飞飞的判断是：==如果塑造AI未来的只是一小群背景相似的工程师，那么AI最终只会服务于一小群人==。这个观点在今天听起来像是共识，但在她提出的时候远不是。

她的身份本身就是一种声明：华裔移民、女性、曾经的底层打工者。在一个长期被白人男性主导的领域里，她的存在改变了"AI科学家应该长什么样"的刻板印象。她不喜欢被标签化，但她也很清楚，==她走过的每一步都在为后来者打开一扇门==。

## 人生地图

一九七六年，李飞飞出生在北京，在成都长大。父亲是一名工程师，对科学有着安静但深沉的热爱；母亲受过良好教育，热爱自然和文学，会带着年幼的飞飞观察花草和昆虫。这个细节后来变得意味深长——多年以后当李飞飞试图让机器理解图像中的内容时，她反复回想的正是童年那种用眼睛去"看"世界的原初体验。母亲教会她的不是知识，而是一种看待世界的方式：充满好奇、不急于下结论、愿意停下来仔细观察。

一九九二年，十六岁的李飞飞随父母移民美国，落脚在新泽西州帕西帕尼。这不是一个光鲜的移民故事。父亲做相机修理工，母亲在中餐馆当收银员，后来全家又开过干洗店。李飞飞自己也在中餐馆打工，一边端盘子一边背英语单词。她几乎不会说英语，在高中是个格格不入的沉默外来者。但她的数学和物理成绩好到老师们无法忽视，最终拿到了普林斯顿大学的奖学金。

普林斯顿打开了一个新世界。她最初学物理，被宇宙的优雅法则吸引，但逐渐意识到自己更想理解一个不同的谜题：人类的大脑是怎样把光信号变成"看见"的？这个问题把她从物理学引向了计算机科学和认知神经科学的交叉地带。大学期间，她曾回到中国在西藏进行草药研究，也曾在高盛拿到报酬丰厚的实习机会。但她最终选择了读博——选择了一条回报不确定、路途漫长的学术道路。

在加州理工学院，她师从计算神经科学先驱Pietro Perona，开始了对视觉识别的系统研究。博士期间和之后在斯坦福的早期教职生涯中，她渐渐形成了一个在当时看来离经叛道的判断：AI领域过度关注算法，严重低估了数据的重要性。这个判断最终催生了ImageNet。二零零七年到二零零九年间，她组织了一个庞大的图像标注项目，利用Amazon Mechanical Turk平台让全球的众包工人标注了超过一千四百万张图片。这个项目几乎没有人看好，但它最终改变了一切。

## 关键转折点

### 移民落差：在新泽西的重建

一九九二年的帕西帕尼对十六岁的李飞飞来说是一个完全陌生的世界。没有朋友，不会说英语，父母的收入勉强维持一家人的基本生活。她在书中回忆了一个画面：放学后赶去中餐馆帮忙，在后厨油腻的灶台旁边摊开课本背单词，窗外是一个她尚未真正进入的国家。

> [!tip]
> 移民经历在李飞飞的人生中不是一个可以翻过去的章节——它成了她所有后续选择的底色。她后来在学术界反复强调AI的"可及性"和"多样性"，不是因为读了什么理论文献，而是因为她亲身经历过被排斥在主流之外是什么感受。当你不会说这个国家的语言、不懂这个国家的规则、在同龄人中间像个隐形人的时候，你对"谁被包括在内、谁被排除在外"的敏感程度会远超那些从未体验过边缘感的人。

这段经历还塑造了她身上一种不容易被注意到的品质：==对不确定性的极高耐受力==。一个十六岁的女孩，在完全陌生的环境中，没有退路，只能一步一步往前走——不知道下一步是什么，但知道停下来不是选项。这种在不确定中持续行动的能力，后来在她推动ImageNet这个"没人看好的项目"时反复发挥了作用。

### 普林斯顿的分岔路：放弃安全选择

拿到普林斯顿奖学金对李飞飞家庭来说是一个转折——但进入普林斯顿之后，她面对的是一个更深层的选择。她在华尔街的面试中表现出色，高盛向她伸出了橄榄枝。对于一个移民家庭来说，这意味着经济问题的一劳永逸的解决。父母的健康状况不好——尤其是母亲后来被诊断出严重的心脏病——这让赚钱养家的压力始终压在她肩上。

但她选择了读博。这个决定在外人看来或许浪漫，但对当事人来说充满了实际的痛苦。选择学术意味着选择延迟回报，意味着在父母最需要经济支持的时候选择了一条收入微薄的道路。她后来在书中坦承，这个选择让她长期背负着对父母的歉疚感。但驱动她的是一个她无法压制的问题：人类的视觉系统到底是怎么工作的？为什么一个婴儿能毫不费力地认出妈妈的脸，而最强大的计算机在最简单的图像面前都束手无策？

> [!note]
> 这里值得注意的是，李飞飞选择学术不是因为她对金钱不在意——恰恰相反，她比大多数同龄人都更清楚钱的重要性。她在中餐馆刷碗、在干洗店熨衣服的每一个小时都在提醒她金钱意味着什么。她的选择之所以值得尊重，正是因为她清楚自己放弃了什么。==一个从未缺过钱的人放弃高薪去做研究，和一个在贫困中挣扎过的人做出同样的选择，这两件事的重量完全不同。==

### ImageNet：一个"没人看好"的赌注

二零零六年前后，李飞飞在斯坦福获得了助理教授的职位，但她面对的学术环境并不友好。计算机视觉在当时是一个公认的"困难且不热门"的方向，大多数AI研究者都在研究算法的改进。学术界的主流共识是：只要算法足够聪明，少量精心挑选的数据就够了。

李飞飞的判断正好相反。她从认知科学的研究中得到了一个关键洞察：人类的视觉系统之所以强大，不是因为大脑的"算法"有多精妙，而是因为从出生起，人的眼睛就在接收海量的视觉数据——==一个婴儿在学会说话之前已经"看过"了数以亿计的图像==。如果机器也想学会"看"，它需要的不仅仅是更好的算法，更是规模足够大、类别足够丰富的视觉数据。

这个想法在当时几乎得不到任何支持。申请经费被拒绝。同事们善意地劝她把精力放在更"安全"的课题上——她还没拿到终身教职，一个助理教授把时间花在一个大家不看好的数据标注项目上，这在学术生涯的策略上几乎是自杀行为。但她还是做了。

技术上的挑战同样巨大。要标注一千四百万张图片，用传统方式需要几十年时间。直到她的一个学生发现了Amazon Mechanical Turk——一个可以将微小任务分发给全球众包工人的平台——ImageNet项目才找到了可行的落地方式。来自一百六十七个国家的四万多名标注者参与了这个浩大的工程。每张图片都经过多人交叉验证，以确保标注的准确性。

> [!warning]
> ImageNet在二零零九年首次发表时，学术界的反应是冷淡的。论文的引用量在最初几年很低。很多人觉得这只是一个"数据工程项目"，缺乏理论深度。这段经历对李飞飞来说无疑是煎熬的——你做了一件你相信重要的事，但同行并不认同它的价值。直到2012年深度学习革命爆发，人们才回过头来意识到ImageNet的基础性意义。

### 2012年的爆发：AlexNet与深度学习革命

二零一零年，李飞飞和她的团队启动了ImageNet大规模视觉识别挑战赛（ILSVRC）。最初几年，参赛团队使用传统的计算机视觉方法，错误率的下降是缓慢的。然后是2012年——多伦多大学的Alex Krizhevsky和他的导师Geoffrey Hinton提交了一个基于深度卷积神经网络的模型AlexNet，将错误率从百分之二十五以上骤降到百分之十六左右。

这个结果震动了整个领域。AlexNet不是在ImageNet上"赢了比赛"那么简单——它证明了两件事：第一，深度神经网络在足够大的数据集上可以展现出远超传统方法的性能；第二，数据的规模和质量确实是决定性的因素之一。没有ImageNet提供的海量标注数据，AlexNet的训练根本无从谈起。

李飞飞在书中描述这一刻时，笔触既兴奋又审慎。她没有把自己塑造成先知——她坦承当AlexNet的结果出来时，她和所有人一样被震惊了。她知道数据很重要，但深度网络在大数据上展现的能力超出了她的预期。这种诚实是这本书最有价值的品质之一：她不假装自己预见了一切，而是如实记录了科学发现中那种==计划与偶然交织、信念与惊讶共存==的真实状态。

2012年之后，深度学习像一场洪水席卷了整个AI领域。ImageNet挑战赛成了每年全球AI研究者竞技的顶级舞台。李飞飞从一个"做冷门方向的年轻教授"变成了AI革命的关键推动者之一。但她很快意识到，技术的爆发性进步带来的不全是好消息——当AI变得越来越强大时，谁在制造它、它为谁服务、它可能伤害谁，这些问题变得越来越紧迫。

### 谷歌云：学术界与产业界的碰撞

二零一七年，李飞飞以首席科学家的身份加入谷歌云。这是她职业生涯中最具争议性的一段经历。她从学术界的自由空间走进了一家万亿级别的商业公司，面对的是一套完全不同的游戏规则。在大学里，你的目标是发表论文、推进知识边界；在公司里，你的价值最终要体现为产品和利润。

在谷歌云期间，她推动了AI工具的民主化——让中小企业和非技术背景的用户也能使用机器学习服务。但她同时也经历了科技公司在AI伦理问题上的内部角力。谷歌与美国国防部的Project Maven合作引发了大规模的员工抗议，李飞飞发现自己处在了一个尴尬的位置：她个人对AI军事化应用有着明确的保留态度，但作为公司的高管，她的发言空间是受限的。一封关于此事的内部邮件后来被泄露给媒体，引发了外界对她立场的误读和批评。

> [!note]
> 这段经历让她深刻认识到，==学术界的理想主义和产业界的现实逻辑之间存在着无法用善意弥合的结构性张力==。一个科学家在公司里能做的事情，受到商业利益、公关策略和组织政治的多重约束。她后来离开谷歌回到斯坦福，很大程度上是因为她意识到，自己想要推动的那种关于AI方向的根本性对话，在一家商业公司里是很难真正展开的。

### 创建HAI：把"以人为本"从口号变成制度

回到斯坦福后，李飞飞做了她职业生涯中最具前瞻性的一个决定：与前斯坦福教务长John Etchemendy一起创建了以人为本AI研究院（HAI）。这个研究院的核心理念是：AI的发展不能只由计算机科学家来主导，必须引入哲学、伦理学、法学、社会学、心理学等多学科的视角。

这个选择在当时的AI学术界是需要勇气的。主流的AI研究者对"跨学科"的态度通常是礼貌的漠视——大家觉得这些"软性"讨论很好，但真正推动领域进步的还是技术论文。李飞飞的判断是：==如果我们等到技术造成了不可逆的伤害再来讨论伦理，那就太晚了==。HAI的目标是让伦理思考和技术开发同步进行，而不是作为事后的补丁。

她在书中详细记述了HAI如何推动美国政策制定者关注AI的社会影响，如何促进AI教育的多样性，如何试图打破科技行业在种族、性别和阶层上的同质性。这些努力的成效不像一篇论文那样可以量化，但它们代表了一种不同的思考方式：技术的进步不仅仅是性能指标的提升，更是关于这种进步最终服务于谁的问题。

## 成就解码

李飞飞的成就建立在几个关键的能力之上。

第一是她的跨学科直觉。她从物理学入门，经由认知神经科学抵达计算机视觉，最后将人文社科引入AI的讨论框架。这种跨越不同知识领域的能力让她能看到单一学科内部的人看不到的盲区。ImageNet的灵感不是来自计算机科学内部——它来自她对人类视觉发育过程的认知科学理解。HAI的创建也不是一个纯技术决策——它来自她作为移民和少数群体的切身感受。李飞飞的特殊之处在于，她从来没有把自己的"非主流"背景视为劣势，而是把它转化成了一种独特的认知优势：正因为她曾经是局外人，她才能看到局内人习以为常的问题。

第二是她在不被认可时坚持自己判断的能力。ImageNet项目在初期几乎得不到任何支持——没有经费，没有同行的认可，还可能影响她获得终身教职。在这种压力下坚持做自己认为正确的事，需要的不只是学术自信，更是一种对自身直觉的深层信任。这种信任不是盲目的固执——她在书中展示了大量的自我怀疑和焦虑——而是一种在怀疑中依然行动的能力。

第三是她把个人经历转化为制度建设的能力。很多人在遭遇不公或困难时会选择个人的适应和超越，但李飞飞走了更远一步：她试图改变产生这些困难的结构本身。她推动AI教育的多样性，不只是因为她自己作为少数群体经历过困难，更是因为她认识到，如果AI的开发者群体不够多元，AI的产品就会内嵌偏见。从个人经历到系统性倡导，这种转化需要超越个人叙事的思维格局。

## 争议与阴影

李飞飞不是一个没有争议的人物，而这本自传也并非完美无缺。

最明显的争议来自她在谷歌云期间的经历。Project Maven事件暴露了学术理想与企业现实之间的裂缝。批评者认为她不应该加入一家可能将AI用于军事目的的公司，或者至少应该更公开地表达反对立场。她在内部邮件中表现出的对公关风险的顾虑——而不是对伦理原则的坚持——让一些人质疑她的"以人为本"理念是否只是说说而已。这是她职业生涯中最脆弱的一个点，也是她在书中处理得相对谨慎的一个部分。

ImageNet本身也面临了越来越多的批评。数据集中存在的标注偏见——某些类别对特定文化、种族或性别的呈现不均衡——引发了关于"大数据本身是否中立"的深刻讨论。利用众包工人进行大规模标注的做法也引起了关于数据劳动伦理的争议：那些来自发展中国家的标注者获得的报酬是否公平？他们的劳动在AI发展的叙事中是否被充分承认？李飞飞在书中对这些问题有所涉及，但批评者认为她的回应不够深入。

这本自传在叙事上有一个值得注意的倾向：它对李飞飞的成长和成就的叙述非常生动，但对她的失误和局限的反思相对节制。作为一本自传，这种倾向可以理解——每个人讲述自己的故事时都有盲区。但读者需要意识到，这里呈现的是李飞飞眼中的世界，不是世界的全貌。她在书中多次强调合作和团队的重要性，但具体到哪些关键贡献来自她的学生和合作者，叙述中的分配有时并不清晰。

## 对你的启示

李飞飞的故事中最有借鉴价值的，不是她的天赋或运气，而是她处理"不被认可"的方式。当你在工作中提出了一个你相信正确但同事和上级都不看好的想法时，你通常会怎么做？大多数人会放弃，或者调整自己去适应主流看法。李飞飞的做法不同：她不是固执地无视所有反对意见，而是仔细评估这些反对意见是否触及了她想法的核心——如果没有，她就继续做，同时不断寻找让别人理解她想法的方式。ImageNet从被冷落到被认可的过程，本质上是一个"如何在不被理解的情况下持续创造价值"的案例。

她的移民经历也提供了一个值得思考的视角：你生命中那些看起来最不利的条件——贫困、语言障碍、身份焦虑——是否有可能在某种程度上成为你独特的认知资源？李飞飞在干洗店和中餐馆里度过的那些时光没有让她变成受害者，而是让她对"谁被包括、谁被排除"这个问题有了一种来自身体记忆的敏感。当你下次感到自己因为某种背景或身份处于劣势时，试着问自己：这段经历是否给了你一种大多数人不具备的观察角度？

最后，她关于AI的核心关切值得每一个与技术打交道的人认真对待：==技术本身没有价值观，但制造技术的人有==。当你参与任何技术产品的设计、开发或推广时，问自己一个问题：这个产品最终会让谁受益、让谁受损？这不是一个可以留给"伦理委员会"去回答的问题——它是每一个参与者都应该思考的问题。

## 延伸阅读

[[《刷新》]]是微软CEO萨提亚·纳德拉的自传，同样讲述了一个移民背景的科技领袖如何在巨头公司内部推动文化变革，与李飞飞在谷歌的经历形成了有趣的对照。[[《AI新生》]]（Life 3.0）是麻省理工学院教授迈克斯·泰格马克对AI未来的系统性思考，如果你被李飞飞关于"以人为本AI"的理念所触动，这本书提供了更深入的哲学和技术分析框架。如果你对移民经历如何塑造一个人的思维和创造力这个主题特别感兴趣，黄仁勋的成长故事——同样是华裔移民、同样在AI领域产生了巨大影响——是一个值得对读的参照。两个人的路径截然不同：一个走向了学术和公共政策，另一个建造了一个算力帝国，但他们的起点有着惊人的相似。
