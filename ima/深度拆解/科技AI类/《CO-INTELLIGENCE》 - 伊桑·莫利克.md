# 《CO-INTELLIGENCE》深度读书笔记

> 2024年，宾夕法尼亚大学沃顿商学院教授伊桑·莫利克写了一本关于如何与AI共处的书，但它不是一本技术指南，也不是一本未来预测。莫利克要做的事情更为根本：他试图说服你，AI不是一件工具，而是一种新型的智能体——它能够参与思考、创造和决策，只不过方式与人类截然不同。这个判断改变了问题的性质。如果AI只是工具，你要学的是"如何使用它"；如果AI是一种共同智能（co-intelligence），你要学的是"如何与它协作"。莫利克提出了四条与AI协作的基本原则：始终邀请AI参与、让人类保持在回路中、像对待一个人一样对待AI但告诉它应该扮演什么角色、假设你现在用的是你这辈子会用到的最差的AI。这四条原则构成了一个既务实又富有前瞻性的框架，帮助你在AI能力飞速提升的时代找到人类的位置。莫利克的核心判断简洁有力——AI时代的核心竞争力不是与AI竞争，而是与AI协作的能力。

## 作者凭什么说这些

伊桑·莫利克是宾夕法尼亚大学沃顿商学院的副教授，专注于创新与创业研究。但让他在AI领域获得巨大影响力的，不是他的学术头衔，而是他在2022年底ChatGPT横空出世后所做的事情。

当大多数学者还在争论大语言模型究竟是"随机鹦鹉"还是"涌现智能"的时候，莫利克已经在自己的课堂上做了一件激进的事情：他要求所有学生在课程作业中使用AI，并把使用效果作为评估的一部分。这不是一个技术极客的冲动决定，而是一位研究创新扩散的学者在亲身测试一项颠覆性技术后做出的理性判断。

莫利克和波士顿咨询集团合作的那项研究引起了广泛关注。他们让数百名咨询顾问分成两组完成真实的咨询任务——一组使用GPT-4，另一组不使用。结果显示，使用AI的咨询顾问在任务完成质量上提升了约40%，完成速度也大幅提高。这不是实验室里的概念验证，而是在真实工作场景中用严格的实验设计得出的结论。这项研究发表后迅速成为讨论AI对工作影响时被引用最多的实证研究之一。

莫利克的另一个独特优势是他的传播能力。他在Substack上运营的"One Useful Thing"博客成为了全球阅读量最大的AI应用类个人专栏之一。他的写作风格清晰直接，既不沉迷于技术细节，也不陷入哲学空谈，而是反复追问一个实际的问题：这项技术今天就能怎么用？这种"研究者兼实践者"的双重身份，让他写出的不是一本隔岸观火的学术著作，而是一本在实战中千锤百炼过的协作手册。

值得注意的是莫利克的学科背景。他不是计算机科学家，不是AI研究员，而是一位研究组织行为和创新的商学院教授。这意味着他看AI的视角天然不同——他关心的不是模型参数和训练方法，而是这项技术如何改变人类的工作方式、组织结构和创造过程。这个视角在2024年的AI讨论中是稀缺的，因为大部分关于AI的书要么由技术专家写成，充满术语和架构图，要么由未来学家写成，充满宏大叙事和末日想象。

## 技术叙事的主线

你可能已经读了不少关于AI的文章和书籍，但大部分陷入了两个极端：要么把AI神化为即将统治世界的超级智能，要么把它矮化为一个高级搜索引擎。莫利克拒绝这两种叙事。他要做的是在恐惧与轻视之间开辟一条中间道路：把AI当作一种真实存在的、能力独特但又有明显缺陷的新型智能来认真对待。

莫利克的论证围绕两根相互交织的线索展开。

第一根线索是认知层面的。他要改变你理解AI的方式。AI不是一个升级版的软件工具——计算器帮你算数、Excel帮你做表格、搜索引擎帮你找信息——它们都是执行明确指令的工具。但大语言模型不同，它能够生成你没有预料到的内容、提出你没有想到的角度、用你没有指定的方式完成你给出的任务。当一个系统开始展现出主动性、创造性和不可预测性时，把它当作"工具"来理解就不够了。莫利克用"共同智能"这个概念来重新框定人与AI的关系——你不是在使用一个工具，你是在与一个不同类型的智能体进行协作。

第二根线索是实践层面的。光有概念转变不够，你还需要具体的操作方法。莫利克用大量亲身实验和教学案例，展示了AI在教育、写作、创意工作、商业决策等领域的实际应用方式。他不给你抽象的"提示词工程"技巧，而是通过一个个具体场景告诉你：在这种情况下，你应该怎么和AI配合，才能得到比任何一方单独行动更好的结果。

这两根线索最终汇聚为一个核心主张：AI时代最重要的能力不是技术能力，也不是传统意义上的专业能力，而是与AI协作的能力——知道什么时候该让AI介入、什么时候该靠自己判断、如何给AI设定角色和边界、如何审查和改进AI的输出。莫利克称之为"共同智能力"（co-intelligence），这是他整本书的思想内核。

## 核心趋势深度解读

### 四条原则：一个应对AI不确定性的操作系统

莫利克没有试图给你一个关于AI未来的宏大预言，因为他很清楚，在一个技术每六个月就迭代一次的领域，任何具体预测都可能迅速过时。他给出的是一套原则——一个足够灵活、能够适应AI持续进化的思维框架。

第一条原则是"始终邀请AI参与"。这条原则的意思不是让你在所有事情上都依赖AI，而是让你养成一个习惯：在开始任何工作之前，先想一想AI能不能在其中发挥作用。大多数人使用AI的方式是"遇到困难时求助"，但莫利克的主张是把AI变成你默认的起点。写一份商业计划？先让AI生成一个初稿框架。分析一组数据？先让AI做一个初步的模式识别。准备一次演讲？先让AI帮你头脑风暴可能的角度。这不是偷懒，而是利用AI快速生成初始方案的能力来加速你自己的思考——AI给出的初稿往往不够好，但它能帮你跳过从零开始的冷启动阶段。

第二条原则是"让人类保持在回路中"。AI擅长快速生成内容和方案，但它不具备判断力、价值观和对上下文的深层理解。你的角色不是被AI替代，而是成为那个判断AI输出质量、决定哪些建议值得采纳、哪些需要修正的人。莫利克在沃顿商学院的教学实验中反复观察到一个现象：学生使用AI后，最容易犯的错误不是AI给了错误答案，而是学生不加审查地接受了AI的输出。人类在回路中最重要的功能，恰恰是保持批判性思维。

第三条原则是"像对待一个人一样对待AI，但告诉它应该扮演什么角色"。这是四条原则中最具争议性的一条，也是最有实操价值的一条。莫利克不是在主张AI有人格或感情，他的观点纯粹是实用主义的：大语言模型是在人类产生的文本上训练的，它对人类交流方式的反应模式更好。当你给AI设定一个具体的角色——"你是一位经验丰富的市场营销专家"或者"你是一位严格的学术审稿人"——AI的输出质量和针对性会显著提升。角色设定本质上是在激活模型在训练数据中学到的特定领域的知识和表达模式。

第四条原则是"假设你现在用的是你这辈子会用到的最差的AI"。这条原则的深意在于：AI的能力在持续快速提升。如果你因为今天的AI不够好就决定不去学习如何与它协作，那么当明天更强大的AI出现时，你就会发现自己完全没有准备。莫利克用一个生动的类比来解释这一点：1990年代的互联网慢得让人绝望，搜索结果粗糙得几乎没用——但那些在1990年代就认真学习如何利用互联网的人，在2000年代互联网爆发时获得了巨大的先发优势。

### AI对教育的颠覆：当考试和作业失去意义

莫利克对教育领域的分析是全书中最尖锐的部分之一，因为这是他自己每天面对的现实。

他直言不讳地指出，AI已经从根本上动摇了现代教育体系的两根支柱：考试和作业。当一个学生可以在几秒钟内用AI生成一篇质量尚可的论文、解答一道复杂的数学题、或者完成一份商业案例分析时，这些传统的评估方式就失去了它们原本的功能——它们不再能有效地衡量学生是否真正掌握了知识和技能。

莫利克在自己的课堂上做了一系列实验。他让学生用AI完成传统作业，结果发现AI在大多数商学院课程作业上的表现可以达到B+甚至A-的水平。这意味着，如果你的教学目标是让学生达到B+的水平，AI已经可以帮他们"作弊"到那个程度。但莫利克没有选择封堵这条路——他选择了拥抱它。他重新设计了课程，不再把"独立完成作业"作为核心要求，而是要求学生展示他们如何与AI协作来解决问题，并且必须在提交作业时附上他们与AI的完整对话记录。

这个转变的深层逻辑是：在一个AI随时可用的世界里，教育的目标不再是把知识装进学生的脑袋，而是培养学生与AI协作来解决复杂问题的能力。记忆事实、执行标准流程、生成格式化文本——这些传统教育最重视的能力，恰恰是AI做得最好的事情。教育需要转向培养AI做不好的能力：提出正确的问题、判断AI输出的质量、在多个AI建议之间做出符合具体情境的选择、以及在AI无法处理的高度不确定性和伦理模糊地带做出决策。

莫利克也看到了AI在教育中的积极潜力。AI可以成为一个永远有耐心、永远不评判的辅导老师——它可以为每个学生提供定制化的学习路径，以学生能够接受的速度和方式解释概念，无限次地回答"愚蠢的问题"。在传统教育中，这种一对一的深度辅导只有富裕家庭才负担得起。AI有可能让高质量的个性化教育变得普及——这是他对教育未来最乐观的判断。

### AI对工作的影响：不是替代，而是重新定义

莫利克和波士顿咨询集团的那项实验是这本书中实证分量最重的部分。数百名咨询顾问被随机分成两组，在真实的咨询项目上工作。使用GPT-4的那组在创意生成、分析质量和写作水平上都表现出了约40%的提升，完成速度也更快。

但实验中还有一个更微妙、也更重要的发现。在提升幅度上，原本表现较弱的咨询顾问获益更大——AI把他们的工作质量拉到了接近优秀咨询顾问的水平。而原本就很优秀的咨询顾问，虽然也从AI中获益，但提升幅度相对较小。莫利克把这称为AI的"拉平效应"——它缩小了高绩效者和低绩效者之间的差距。

这个发现对职场的影响是深远的。如果AI能让一个普通员工产出接近优秀员工水平的工作成果，那么"优秀"的定义就需要改变。在AI时代，仅仅把工作做得"很好"不再是足够的竞争优势——因为AI可以帮助几乎任何人做到"很好"。真正的竞争优势转移到了AI无法替代的领域：对问题的深层理解、跨领域的整合能力、对人类需求的细腻感知、以及在高度不确定的情境中做出判断的能力。

但实验中也出现了一个让人警觉的现象。当任务本身超出了AI的能力边界——比如需要基于特定的、AI训练数据中没有涵盖的信息做出判断时——使用AI的那组反而表现得更差。原因是，很多咨询顾问过度信任了AI的输出，没有对AI的回答进行足够的审查和修正。AI给出了一个看起来合理但实际上错误的分析，而人类因为"自动化偏见"接受了它。

这个实验揭示了AI对工作影响的双重性质：它既是能力放大器，也是判断力的潜在削弱器。最终决定你是从AI中获益还是受损的，不是AI本身的能力，而是你与AI协作的方式。

### AI的创造力：它不是在模仿，它在做某种不同的事情

关于AI能不能"创造"，大多数讨论陷入了一个非此即彼的争论：乐观者说AI已经具备创造力，悲观者说AI只是在重新排列组合它见过的内容。莫利克的分析比这两种立场都更为精细。

他通过大量实验发现，AI在创意任务上的表现呈现出一种独特的模式：AI擅长生成大量中等偏上质量的创意，但很少产出真正突破性的、出人意料的创意。如果你需要在十分钟内想出二十个营销创意，AI几乎肯定比任何一个人类做得更好——它的数量和速度是压倒性的，而且平均质量不低。但如果你需要那一个让所有人眼前一亮的天才创意，AI往往给不了你——它的输出倾向于落在"已知模式的优雅组合"范围内，而真正的创造性突破往往来自打破已知模式。

这个发现的实践意义是：AI最佳的创造性应用不是替代人类的创意工作，而是改变创意工作的流程。在传统的创意过程中，最耗费精力的往往不是那个"灵光一闪"的时刻，而是之前大量的素材收集、方案生成和初稿迭代。AI可以极大地压缩这些前期准备工作的时间，让人类把精力集中在真正需要人类判断和直觉的环节——评估、选择、修正和突破。

莫利克还观察到一个有趣的现象：当人类和AI在创意过程中反复交互——人类提出方向、AI生成方案、人类反馈和调整、AI再次迭代——最终的产出往往优于任何一方独立工作的结果。这种协作式的创造过程，正是"共同智能"概念的最佳体现。

### AI的局限性：幻觉、偏见和不确定的边界

莫利克对AI局限性的讨论没有陷入技术细节，而是从用户体验的角度切入——你在使用AI时最容易踩哪些坑？

第一个也是最严重的问题是"幻觉"。AI会以极其自信和流畅的语气告诉你完全错误的信息。它会编造不存在的学术论文、虚构不存在的历史事件、给出听起来完全合理但实际上错误的数据。问题的根源在于大语言模型的本质：它是一个统计模式匹配系统，它的目标是生成"听起来最合理"的文本，而不是"最准确"的文本。"听起来合理"和"实际准确"之间的差距，就是幻觉产生的空间。

更棘手的是，你无法通过AI自身来判断它是否在"幻觉"。当你问AI"你确定这是对的吗"，它几乎总会说"是的"——因为从统计模式的角度，"肯定自己的回答"是最常见的语言模式。AI没有真正的自我审查能力，它无法区分自己什么时候在陈述事实、什么时候在编造。这意味着，对AI输出的事实核查责任完全落在人类身上——这是"人类在回路中"原则最重要的应用场景。

第二个问题是偏见。AI在训练数据中吸收了人类文本中存在的各种偏见——性别偏见、种族偏见、文化偏见。当你让AI生成一个"CEO"的形象描述时，它倾向于给出一个白人男性的形象。当你让AI评估两份简历时，隐含在训练数据中的偏见可能会影响它的判断。莫利克指出，这些偏见不是AI的"错误"，而是它忠实地反映了人类社会现有的偏见——但当这些偏见被嵌入到一个被大规模使用的技术系统中时，它们的影响会被急剧放大。

第三个问题是AI能力边界的不确定性。你永远不确定AI在什么时候会突然"失灵"——它可能在一个复杂的法律分析任务上表现出色，但在一个看似简单的数学计算上犯低级错误。这种不可预测性使得你无法简单地划定"AI擅长什么"和"AI不擅长什么"的边界——这个边界是模糊的、动态的、随模型版本更新而变化的。莫利克的建议是：不要试图一劳永逸地画出这个边界，而是在每个具体任务上，通过实际测试来评估AI的可靠性。

### 共同智能的哲学：AI不是工具，那它是什么？

莫利克在书中最具思想冲击力的部分，是他对AI本质的重新定义。

传统的理解方式有两个极端。一端是把AI当作高级工具——它就像一把更快的锤子，本质上和计算器没有区别，只是能处理更复杂的任务。另一端是把AI当作准人类——赋予它意识、意图、甚至道德地位。莫利克认为这两种理解都不对。

AI既不是工具也不是人，它是一种全新的事物——一种能够参与认知过程但不拥有人类式意识的智能体。你和AI之间的关系不是"使用者与工具"的关系，更接近于一种新型的"协作关系"——但协作的对象既不完全理解你在做什么，也不对结果承担任何责任。这种关系在人类历史上没有先例，所以你没有现成的模板可以套用。

莫利克没有在这个哲学问题上纠缠太久——他是一个实用主义者。他关心的不是"AI是否真的具有智能"这个可能永远无法回答的问题，而是"如果我们把AI当作一种共同智能来对待，会不会得到更好的结果"。他的答案是肯定的：当你把AI当作一个有能力但不完美的协作伙伴来对待——给它明确的角色、清晰的任务、具体的约束条件——你得到的结果比把它当作搜索引擎或自动补全工具要好得多。

## 预测的成绩单

《CO-INTELLIGENCE》出版于2024年初，到现在不到两年。时间虽短，但AI领域的迭代速度之快，已经让我们有机会对莫利克的一些核心判断做初步的现实检验。

被快速验证的判断有几个方面。AI对工作效率的提升效应正在大规模展现。从编程到客服、从法律文档到医疗记录，越来越多的职业领域开始系统性地整合AI工具，而报告出的效率提升幅度与莫利克引用的40%研究结论大体一致。AI的"拉平效应"也在不同行业中得到了观察——在编程领域，GitHub Copilot的使用数据显示，初级程序员从AI辅助中获得的效率提升明显高于高级程序员。教育领域的震荡同样按照莫利克描述的轨迹在展开——全球范围内的大学正在重新设计考试形式和作业要求，以回应AI对传统评估方式的冲击。

需要观察的判断也不少。莫利克对AI创造力的评估——"大量中等偏上，但缺乏突破性"——可能正在被新一代模型挑战。随着模型能力的提升，AI在某些创意领域（如视觉艺术、音乐生成）的输出质量已经开始让部分专业创作者感到不安。莫利克的"第四原则"——假设这是最差的AI——被一次又一次地验证着：每一代新模型都让前一代看起来显得笨拙，而学会与"较差的"AI协作的人确实在新模型出现时适应得更快。

莫利克对AI局限性的分析——尤其是幻觉问题——至今仍然成立。尽管各家模型公司都在努力降低幻觉率，但这个问题的根本性质并没有改变：大语言模型生成文本的方式决定了它无法从结构上杜绝幻觉。莫利克的建议——始终保持人类审查——依然是对待AI输出最明智的态度。

## 技术之外的思考

莫利克在这本书中没有回避AI带来的深层社会问题，但他的处理方式和大多数AI警告派不同——他不是在预言灾难，而是在描述你必须面对的现实复杂性。

在就业层面，莫利克的分析比"AI会抢走你的工作"这种简单叙事要细腻得多。他指出，AI对就业的影响不是"替代"，而是"重新定义"。很多工作不会消失，但工作的内容和技能要求会发生根本性的变化。翻译不会消失，但"翻译"这个角色从"把一种语言转换为另一种语言"变成了"审校和优化AI的翻译输出"。这种转变对个人的要求不是更低，而是更高——你不仅需要懂两种语言，还需要懂AI翻译的模式和局限性。

在公平性层面，莫利克注意到一个值得关注的张力。AI的"拉平效应"从某种角度看是积极的——它让普通人也能产出接近专家水平的工作成果，这是一种民主化。但从另一个角度看，它可能加剧另一种不平等——能够获取和善用AI工具的人与不能获取或不会使用AI的人之间的鸿沟。AI不是自动的平等化力量，它是一个放大器——它放大已有的优势，也放大已有的劣势。

在伦理层面，莫利克提出了一个在其他AI著作中很少被正面讨论的问题：当AI的输出越来越像人类时，我们在多大程度上应该向他人披露AI的参与？一份AI辅助撰写的商业提案、一篇AI辅助完成的学术论文、一段AI辅助创作的音乐——在什么程度上需要标注AI的贡献？这个问题没有简单的答案，但莫利克认为社会需要尽快就此展开严肃的对话，而不是等到问题积累到不可收拾时才被迫应对。

## 对你意味着什么

读完这本书，你对AI的理解和使用方式应该发生几个具体的转变。

你会停止把AI当作搜索引擎的升级版。搜索引擎帮你找信息，AI帮你处理信息——这两者之间的差距不是程度上的，而是性质上的。当你把AI当作"能回答问题的东西"时，你只使用了它很小一部分的能力。当你把它当作一个"能参与你的思考过程的协作者"时，你会发现它的用途远比你想象的广泛——帮你模拟对手的反驳论点、帮你从不同角色的视角审视一个方案、帮你把一个模糊的想法具体化为一个可执行的计划。

你会建立一种新的工作习惯——在开始任何需要创造性思考或信息处理的工作之前，先花几分钟和AI对话。这不是偷懒，这是利用一种新型智能资源来加速你自己的认知过程。但你同时会保持一种清醒的审慎——AI给出的任何事实性陈述都需要核查，AI提出的任何建议都需要你用自己的专业判断来评估。

你还会意识到，学会与AI协作不是一件可以拖延的事情。莫利克的第四条原则意味着：今天的AI虽然不完美，但它正在以每隔几个月就显著进步的速度进化。那些今天就开始认真学习人机协作的人，会在未来更强大的AI出现时拥有决定性的先发优势。

## 延伸阅读

吴军的《智能时代》从大数据和机器智能的技术原理层面理解AI的底层逻辑，与莫利克侧重应用和协作的视角形成互补。迈克斯·泰格马克的《生命3.0》关注的是AI的长远未来对人类意味着什么——如果莫利克处理的是"今天如何与AI协作"的问题，泰格马克处理的是同一话题在更长时间尺度上的延伸。李开复的《AI超级力量》则从中美AI竞争和产业布局的角度审视AI的发展，提供了莫利克这本书缺少的地缘政治维度。