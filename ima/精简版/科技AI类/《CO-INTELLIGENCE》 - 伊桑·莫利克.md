# 《CO-INTELLIGENCE》精华速览

> 宾夕法尼亚大学沃顿商学院教授伊桑·莫利克在2024年提出了一个改变AI讨论框架的核心主张：AI不是工具，而是一种新型的共同智能（co-intelligence），你需要学会的不是"如何使用它"，而是"如何与它协作"。他给出了四条经得起AI持续进化考验的协作原则，并用严格的实证研究证明AI可以让咨询顾问的工作质量提升约40%。他的核心判断是——AI时代的核心竞争力不是与AI竞争，而是与AI协作的能力。

## 关于这本书

伊桑·莫利克是沃顿商学院副教授，研究创新与创业。他在2022年底ChatGPT发布后迅速成为全球最具影响力的AI应用研究者之一——他要求自己课堂上的所有学生在作业中使用AI，并与波士顿咨询集团合作完成了一项广受引用的实证研究，证明AI能显著提升知识工作者的绩效。他在Substack上运营的"One Useful Thing"博客是全球阅读量最大的AI应用类个人专栏之一。莫利克不是计算机科学家，他的视角天然不同于大多数AI著作的作者——他关心的不是模型参数和训练方法，而是AI如何改变人类的工作方式、组织结构和创造过程。这种"研究者兼实践者"的双重身份，让这本书读起来不像学术论文，也不像未来预言，而像一本经过实战检验的人机协作手册。

## 全书逻辑线

全书围绕两根相互交织的线索展开。

第一根是认知层面的重新定义。莫利克认为，把AI当作工具来理解已经不够了。计算器、Excel、搜索引擎——它们都执行明确的指令，不会给出你没有预料到的东西。但大语言模型不同，它能生成出人意料的内容、提出你没想到的角度、用你没指定的方式完成任务。当一个系统展现出主动性、创造性和不可预测性时，它更接近于一个"协作伙伴"而非"工具"。莫利克用"共同智能"这个概念来重新框定人与AI的关系——你不是在使用一个工具，你是在与一种不同类型的智能体协作。

第二根是实践层面的操作方法。莫利克提出了四条协作原则作为应对框架：始终邀请AI参与（把AI变成工作的默认起点而非遇困时的求助对象）、让人类保持在回路中（人类的核心角色是对AI的输出进行审查和判断）、像对待一个人一样对待AI但告诉它扮演什么角色（角色设定能激活模型在特定领域的知识）、假设这是你这辈子会用到的最差的AI（今天开始学习协作的人会在更强AI出现时拥有先发优势）。这四条原则的设计是"超越具体技术版本"的——无论AI如何迭代，这些原则依然适用。

在这两根线索之上，莫利克展开了AI对教育、工作、创造力三个领域的深度分析，并正面讨论了AI的局限性——幻觉、偏见和能力边界的不确定性。全书最终汇聚为一个核心主张：AI时代最重要的能力不是技术能力，也不是传统的专业能力，而是与AI协作的能力。

## 核心观点拆解

### AI的"拉平效应"改变了"优秀"的定义

莫利克与波士顿咨询集团合作的实验是这本书中最有分量的实证。数百名咨询顾问被随机分组，一组使用GPT-4，另一组不使用，在真实咨询项目上工作。使用AI的那组在创意生成、分析质量和写作水平上提升了约40%。但更值得关注的是"拉平效应"：原本表现较弱的咨询顾问获益更大——AI把他们的工作质量拉到了接近优秀咨询顾问的水平，而原本优秀的咨询顾问提升幅度相对较小。这意味着，在AI时代，仅仅把工作做得"很好"不再是足够的竞争优势，因为AI可以帮助几乎任何人做到"很好"。真正的竞争优势转移到了AI无法替代的领域——对问题的深层理解、跨领域整合、对人类需求的细腻感知、以及在高度不确定情境中做出判断。

### 自动化偏见是比AI幻觉更危险的陷阱

实验中还出现了一个让人警觉的现象：当任务超出AI能力边界时，使用AI的那组反而表现更差。原因不在AI本身，而在于人类的"自动化偏见"——当一个看起来权威、流畅、有条理的回答摆在面前时，人天然倾向于接受它，即使它可能包含错误。AI的输出越像"专家的话"，你越容易放松警惕。莫利克反复强调，人类在AI协作中最重要的角色不是"提出好问题"，而是"保持批判性思维"——对AI输出的每一个事实性陈述保持怀疑态度，尤其是在那些你不太熟悉的领域。

### 教育的两根支柱正在被动摇

AI已经可以在大多数商学院课程作业上达到B+甚至A-的水平。莫利克在自己的课堂上亲自验证了这一点。这意味着传统的考试和作业作为评估方式已经失灵——它们无法再有效衡量学生是否真正掌握了知识。莫利克的应对方式不是封堵AI，而是拥抱它：他重新设计课程，要求学生展示与AI的协作过程而非独立完成的结果，并附上完整的对话记录。他认为教育的目标需要根本性转变——从"把知识装进学生脑袋"转向"培养学生与AI协作解决复杂问题的能力"。同时他也看到了AI在教育中的积极潜力：AI可以成为一个永远有耐心、为每个学生定制学习路径的辅导老师，有可能让过去只有富裕家庭才能负担的个性化教育变得普及。

### AI的创造力模式：数量碾压，但缺乏突破

莫利克通过大量实验发现，AI在创意任务上呈现出一种独特模式：它擅长快速生成大量中等偏上质量的创意，数量和速度对人类形成压倒性优势。但它很少产出真正突破性的、出人意料的创意——它的输出倾向于落在"已知模式的优雅组合"范围内。这意味着AI最佳的创造性应用不是替代人类创意工作，而是改变创意流程：AI负责压缩素材收集、方案生成和初稿迭代等前期准备时间，人类把精力集中在评估、选择、修正和真正的突破上。莫利克还观察到，当人类和AI反复交互——人类提出方向、AI生成方案、人类反馈调整、AI再次迭代——最终产出往往优于任何一方独立工作的结果。

### 幻觉问题的本质无法被消除

AI会以极其自信的语气告诉你完全错误的信息——编造不存在的论文、虚构历史事件、给出听起来合理但实际错误的数据。问题的根源在于大语言模型的本质：它是统计模式匹配系统，目标是生成"听起来最合理"的文本而非"最准确"的文本。更棘手的是，你无法通过AI自身来判断它是否在"幻觉"——当你追问"你确定吗"，它几乎总会肯定自己。AI没有真正的自我审查能力。这意味着事实核查的责任完全落在人类身上，这是"人类在回路中"原则最关键的应用场景。

### AI不是工具也不是人，是一种全新事物

莫利克拒绝了两种极端理解。把AI当高级工具（和计算器本质相同）忽略了它的主动性和不可预测性。把AI当准人类（赋予意识和道德地位）则过度解读了它的能力。AI是一种能参与认知过程但不拥有人类式意识的智能体——你和它之间的关系不是"使用者与工具"，更接近一种新型协作关系，但协作对象既不完全理解你在做什么，也不对结果承担责任。莫利克的实用主义立场是：不必纠结AI是否"真的"有智能，只需要观察——当你把它当作有能力但不完美的协作伙伴来对待，给它明确的角色和具体的约束条件时，你得到的结果确实比把它当搜索引擎好得多。

### 第四条原则的深意：时间窗口正在关闭

"假设这是你这辈子会用到的最差的AI"——这条原则表面上是对AI进步速度的描述，深层是对你的行动紧迫性的提醒。莫利克类比1990年代的互联网：当时网速慢得让人绝望，搜索结果粗糙得几乎没用，但那些在那个时代就认真学习如何利用互联网的人，在2000年代互联网爆发时获得了巨大的先发优势。AI正在经历同样的轨迹。今天的AI虽然有种种不完美，但它正以每隔几个月就显著进步的速度进化。那些因为"AI还不够好"就决定暂不学习的人，会在更强大的AI出现时发现自己完全没有准备。

## 这本书的边界

莫利克的商学院教授身份是一把双刃剑。它让他能够用严格的实验设计来检验AI对工作的影响，能够从组织行为学的视角分析人机协作——这些是大多数AI著作缺乏的。但这个身份也带来了视角局限：他的分析主要集中在知识工作领域（咨询、教育、写作、商业决策），对AI在制造业、医疗、科研等领域的影响讨论较少。他对AI技术本身的讨论有意保持在概念层面，不涉及模型架构和训练方法的细节——对技术读者来说可能不够深入。此外，莫利克对AI社会影响的讨论虽然比大多数AI乐观派更为审慎，但他本质上仍是一个"拥抱AI"的倡导者，对AI可能带来的结构性不平等、劳动力市场的剧烈重组、以及数据隐私等问题的讨论力度不足。这本书最适合的读者，是那些已经意识到AI正在改变世界、但还不确定如何将AI融入自己工作流程的知识工作者。

## 读完之后

这本书给你的最核心转变，是从"AI是一个工具"到"AI是一个协作伙伴"的认知升级。这个转变不是语义游戏——它会实质性地改变你与AI互动的方式。你会开始在每一项需要创造性思考或信息处理的工作开始之前花几分钟与AI对话，把它变成你的默认起点。你会学着给AI设定具体角色而非泛泛提问，因为角色设定能激活它在特定领域的知识。你会保持对AI输出的批判性审查，因为你知道幻觉问题在结构上无法被消除。你还会建立一种对技术变革时间窗口的紧迫感——不是焦虑，而是清醒的认知：今天开始学习人机协作的人，会在未来每一次AI升级时比其他人更快地捕获新能力。延伸阅读推荐吴军的《智能时代》（理解AI的技术底层逻辑）、泰格马克的《生命3.0》（AI长远未来的哲学思考）、李开复的《AI超级力量》（AI的地缘政治和产业布局维度）。